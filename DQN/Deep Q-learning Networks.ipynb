{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 0 ***                       \n",
      "Av.reward: [last 10]: 2.50, [last 100]: 0.25, [all]: 25.00                       \n",
      "epsilon: 0.86, frames_total: 25\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 10 ***                       \n",
      "Av.reward: [last 10]: 30.30, [last 100]: 3.28, [all]: 29.82                       \n",
      "epsilon: 0.48, frames_total: 328\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 20 ***                       \n",
      "Av.reward: [last 10]: 19.50, [last 100]: 5.23, [all]: 24.90                       \n",
      "epsilon: 0.33, frames_total: 523\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 30 ***                       \n",
      "Av.reward: [last 10]: 38.80, [last 100]: 9.11, [all]: 29.39                       \n",
      "epsilon: 0.16, frames_total: 911\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 40 ***                       \n",
      "Av.reward: [last 10]: 49.10, [last 100]: 14.02, [all]: 34.20                       \n",
      "epsilon: 0.07, frames_total: 1402\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 50 ***                       \n",
      "Av.reward: [last 10]: 42.00, [last 100]: 18.22, [all]: 35.73                       \n",
      "epsilon: 0.04, frames_total: 1822\n",
      "Elapsed time:  00:00:01\n",
      "\n",
      "*** Episode 60 ***                       \n",
      "Av.reward: [last 10]: 50.70, [last 100]: 23.29, [all]: 38.18                       \n",
      "epsilon: 0.03, frames_total: 2329\n",
      "Elapsed time:  00:00:01\n",
      "\n",
      "*** Episode 70 ***                       \n",
      "Av.reward: [last 10]: 51.20, [last 100]: 28.41, [all]: 40.01                       \n",
      "epsilon: 0.02, frames_total: 2841\n",
      "Elapsed time:  00:00:01\n",
      "\n",
      "*** Episode 80 ***                       \n",
      "Av.reward: [last 10]: 49.00, [last 100]: 33.31, [all]: 41.12                       \n",
      "epsilon: 0.02, frames_total: 3331\n",
      "Elapsed time:  00:00:02\n",
      "\n",
      "*** Episode 90 ***                       \n",
      "Av.reward: [last 10]: 60.00, [last 100]: 39.31, [all]: 43.20                       \n",
      "epsilon: 0.02, frames_total: 3931\n",
      "Elapsed time:  00:00:02\n",
      "\n",
      "*** Episode 100 ***                       \n",
      "Av.reward: [last 10]: 103.10, [last 100]: 49.37, [all]: 49.13                       \n",
      "epsilon: 0.02, frames_total: 4962\n",
      "Elapsed time:  00:00:03\n",
      "\n",
      "*** Episode 110 ***                       \n",
      "Av.reward: [last 10]: 104.90, [last 100]: 56.83, [all]: 54.15                       \n",
      "epsilon: 0.02, frames_total: 6011\n",
      "Elapsed time:  00:00:04\n",
      "\n",
      "*** Episode 120 ***                       \n",
      "Av.reward: [last 10]: 212.30, [last 100]: 76.11, [all]: 67.22                       \n",
      "epsilon: 0.02, frames_total: 8134\n",
      "Elapsed time:  00:00:05\n",
      "\n",
      "*** Episode 130 ***                       \n",
      "Av.reward: [last 10]: 295.40, [last 100]: 101.77, [all]: 84.64                       \n",
      "epsilon: 0.02, frames_total: 11088\n",
      "Elapsed time:  00:00:07\n",
      "\n",
      "*** Episode 140 ***                       \n",
      "Av.reward: [last 10]: 269.60, [last 100]: 123.82, [all]: 97.76                       \n",
      "epsilon: 0.02, frames_total: 13784\n",
      "Elapsed time:  00:00:09\n",
      "\n",
      "*** Episode 150 ***                       \n",
      "Av.reward: [last 10]: 254.20, [last 100]: 145.04, [all]: 108.12                       \n",
      "epsilon: 0.02, frames_total: 16326\n",
      "Elapsed time:  00:00:11\n",
      "\n",
      "*** Episode 160 ***                       \n",
      "Av.reward: [last 10]: 342.10, [last 100]: 174.18, [all]: 122.65                       \n",
      "epsilon: 0.02, frames_total: 19747\n",
      "Elapsed time:  00:00:14\n",
      "SOLVED! After 167 episodes \n",
      "\n",
      "*** Episode 170 ***                       \n",
      "Av.reward: [last 10]: 392.50, [last 100]: 208.31, [all]: 138.43                       \n",
      "epsilon: 0.02, frames_total: 23672\n",
      "Elapsed time:  00:00:17\n",
      "\n",
      "*** Episode 180 ***                       \n",
      "Av.reward: [last 10]: 376.80, [last 100]: 241.09, [all]: 151.60                       \n",
      "epsilon: 0.02, frames_total: 27440\n",
      "Elapsed time:  00:00:19\n",
      "\n",
      "*** Episode 190 ***                       \n",
      "Av.reward: [last 10]: 383.70, [last 100]: 273.46, [all]: 163.75                       \n",
      "epsilon: 0.02, frames_total: 31277\n",
      "Elapsed time:  00:00:22\n",
      "\n",
      "*** Episode 200 ***                       \n",
      "Av.reward: [last 10]: 316.60, [last 100]: 294.81, [all]: 171.36                       \n",
      "epsilon: 0.02, frames_total: 34443\n",
      "Elapsed time:  00:00:24\n",
      "\n",
      "*** Episode 210 ***                       \n",
      "Av.reward: [last 10]: 441.50, [last 100]: 328.47, [all]: 184.16                       \n",
      "epsilon: 0.02, frames_total: 38858\n",
      "Elapsed time:  00:00:27\n",
      "\n",
      "*** Episode 220 ***                       \n",
      "Av.reward: [last 10]: 447.60, [last 100]: 352.00, [all]: 196.08                       \n",
      "epsilon: 0.02, frames_total: 43334\n",
      "Elapsed time:  00:00:31\n",
      "\n",
      "*** Episode 230 ***                       \n",
      "Av.reward: [last 10]: 290.60, [last 100]: 351.52, [all]: 200.17                       \n",
      "epsilon: 0.02, frames_total: 46240\n",
      "Elapsed time:  00:00:33\n",
      "\n",
      "*** Episode 240 ***                       \n",
      "Av.reward: [last 10]: 436.60, [last 100]: 368.22, [all]: 209.98                       \n",
      "epsilon: 0.02, frames_total: 50606\n",
      "Elapsed time:  00:00:36\n",
      "\n",
      "*** Episode 250 ***                       \n",
      "Av.reward: [last 10]: 460.20, [last 100]: 388.82, [all]: 219.95                       \n",
      "epsilon: 0.02, frames_total: 55208\n",
      "Elapsed time:  00:00:39\n",
      "\n",
      "*** Episode 260 ***                       \n",
      "Av.reward: [last 10]: 356.50, [last 100]: 390.26, [all]: 225.18                       \n",
      "epsilon: 0.02, frames_total: 58773\n",
      "Elapsed time:  00:00:42\n",
      "\n",
      "*** Episode 270 ***                       \n",
      "Av.reward: [last 10]: 451.50, [last 100]: 396.16, [all]: 233.54                       \n",
      "epsilon: 0.02, frames_total: 63288\n",
      "Elapsed time:  00:00:45\n",
      "\n",
      "*** Episode 280 ***                       \n",
      "Av.reward: [last 10]: 253.40, [last 100]: 383.82, [all]: 234.24                       \n",
      "epsilon: 0.02, frames_total: 65822\n",
      "Elapsed time:  00:00:46\n",
      "\n",
      "*** Episode 290 ***                       \n",
      "Av.reward: [last 10]: 352.60, [last 100]: 380.71, [all]: 238.31                       \n",
      "epsilon: 0.02, frames_total: 69348\n",
      "Elapsed time:  00:00:49\n",
      "\n",
      "*** Episode 300 ***                       \n",
      "Av.reward: [last 10]: 177.00, [last 100]: 366.75, [all]: 236.27                       \n",
      "epsilon: 0.02, frames_total: 71118\n",
      "Elapsed time:  00:00:50\n",
      "\n",
      "*** Episode 310 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 372.60, [all]: 244.75                       \n",
      "epsilon: 0.02, frames_total: 76118\n",
      "Elapsed time:  00:00:54\n",
      "\n",
      "*** Episode 320 ***                       \n",
      "Av.reward: [last 10]: 461.90, [last 100]: 374.03, [all]: 251.52                       \n",
      "epsilon: 0.02, frames_total: 80737\n",
      "Elapsed time:  00:00:57\n",
      "\n",
      "*** Episode 330 ***                       \n",
      "Av.reward: [last 10]: 280.00, [last 100]: 372.97, [all]: 252.38                       \n",
      "epsilon: 0.02, frames_total: 83537\n",
      "Elapsed time:  00:01:00\n",
      "\n",
      "*** Episode 340 ***                       \n",
      "Av.reward: [last 10]: 357.70, [last 100]: 365.08, [all]: 255.47                       \n",
      "epsilon: 0.02, frames_total: 87114\n",
      "Elapsed time:  00:01:02\n",
      "\n",
      "*** Episode 350 ***                       \n",
      "Av.reward: [last 10]: 369.60, [last 100]: 356.02, [all]: 258.72                       \n",
      "epsilon: 0.02, frames_total: 90810\n",
      "Elapsed time:  00:01:06\n",
      "\n",
      "*** Episode 360 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 370.37, [all]: 265.40                       \n",
      "epsilon: 0.02, frames_total: 95810\n",
      "Elapsed time:  00:01:09\n",
      "\n",
      "*** Episode 370 ***                       \n",
      "Av.reward: [last 10]: 230.50, [last 100]: 348.27, [all]: 264.46                       \n",
      "epsilon: 0.02, frames_total: 98115\n",
      "Elapsed time:  00:01:11\n",
      "\n",
      "*** Episode 380 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 372.93, [all]: 270.64                       \n",
      "epsilon: 0.02, frames_total: 103115\n",
      "Elapsed time:  00:01:14\n",
      "\n",
      "*** Episode 390 ***                       \n",
      "Av.reward: [last 10]: 392.50, [last 100]: 376.92, [all]: 273.76                       \n",
      "epsilon: 0.02, frames_total: 107040\n",
      "Elapsed time:  00:01:17\n",
      "\n",
      "*** Episode 400 ***                       \n",
      "Av.reward: [last 10]: 214.20, [last 100]: 380.64, [all]: 272.27                       \n",
      "epsilon: 0.02, frames_total: 109182\n",
      "Elapsed time:  00:01:18\n",
      "\n",
      "*** Episode 410 ***                       \n",
      "Av.reward: [last 10]: 194.60, [last 100]: 350.10, [all]: 270.38                       \n",
      "epsilon: 0.02, frames_total: 111128\n",
      "Elapsed time:  00:01:20\n",
      "\n",
      "*** Episode 420 ***                       \n",
      "Av.reward: [last 10]: 249.70, [last 100]: 328.88, [all]: 269.89                       \n",
      "epsilon: 0.02, frames_total: 113625\n",
      "Elapsed time:  00:01:21\n",
      "\n",
      "*** Episode 430 ***                       \n",
      "Av.reward: [last 10]: 438.50, [last 100]: 344.73, [all]: 273.81                       \n",
      "epsilon: 0.02, frames_total: 118010\n",
      "Elapsed time:  00:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Episode 440 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 358.96, [all]: 278.93                       \n",
      "epsilon: 0.02, frames_total: 123010\n",
      "Elapsed time:  00:01:28\n",
      "\n",
      "*** Episode 450 ***                       \n",
      "Av.reward: [last 10]: 222.80, [last 100]: 344.28, [all]: 277.69                       \n",
      "epsilon: 0.02, frames_total: 125238\n",
      "Elapsed time:  00:01:29\n",
      "\n",
      "*** Episode 460 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 344.28, [all]: 282.51                       \n",
      "epsilon: 0.02, frames_total: 130238\n",
      "Elapsed time:  00:01:33\n",
      "\n",
      "*** Episode 470 ***                       \n",
      "Av.reward: [last 10]: 500.00, [last 100]: 371.23, [all]: 287.13                       \n",
      "epsilon: 0.02, frames_total: 135238\n",
      "Elapsed time:  00:01:36\n",
      "\n",
      "*** Episode 480 ***                       \n",
      "Av.reward: [last 10]: 310.00, [last 100]: 352.23, [all]: 287.60                       \n",
      "epsilon: 0.02, frames_total: 138338\n",
      "Elapsed time:  00:01:38\n",
      "\n",
      "*** Episode 490 ***                       \n",
      "Av.reward: [last 10]: 151.80, [last 100]: 328.16, [all]: 284.84                       \n",
      "epsilon: 0.02, frames_total: 139856\n",
      "Elapsed time:  00:01:39\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average reward: 286.08\n",
      "Average reward (last 100 episodes): 340.15\n",
      "Solved after 167 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "seed_value = 23\n",
    "env.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "###### PARAMS ######\n",
    "learning_rate = 0.01\n",
    "num_episodes = 500\n",
    "gamma = 0.99\n",
    "\n",
    "hidden_layer = 64\n",
    "\n",
    "egreedy = 0.9\n",
    "egreedy_final = 0.02\n",
    "egreedy_decay = 500\n",
    "\n",
    "report_interval = 10\n",
    "score_to_solve = 195\n",
    "\n",
    "####################\n",
    "\n",
    "number_of_inputs = env.observation_space.shape[0]\n",
    "number_of_outputs = env.action_space.n\n",
    "\n",
    "def calculate_epsilon(steps_done):\n",
    "    epsilon = egreedy_final + (egreedy - egreedy_final) * \\\n",
    "              math.exp(-1. * steps_done / egreedy_decay )\n",
    "    return epsilon\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(number_of_inputs,hidden_layer)\n",
    "        self.linear2 = nn.Linear(hidden_layer,number_of_outputs)\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        #self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output1 = self.linear1(x)\n",
    "        output1 = self.activation(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "\n",
    "        return output2\n",
    "    \n",
    "class QNet_Agent(object):\n",
    "    def __init__(self):\n",
    "        self.nn = NeuralNetwork().to(device)\n",
    "\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        #self.loss_func = nn.SmoothL1Loss()\n",
    "        \n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(), lr=learning_rate)\n",
    "        #self.optimizer = optim.RMSprop(params=mynn.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def select_action(self,state,epsilon):\n",
    "        \n",
    "        random_for_egreedy = torch.rand(1)[0]\n",
    "        \n",
    "        if random_for_egreedy > epsilon:      \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                state = Tensor(state).to(device)\n",
    "                action_from_nn = self.nn(state)\n",
    "                action = torch.max(action_from_nn,0)[1]\n",
    "                action = action.item()        \n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def optimize(self, state, action, new_state, reward, done):\n",
    "        \n",
    "        state = Tensor(state).to(device)\n",
    "        new_state = Tensor(new_state).to(device)\n",
    "        \n",
    "        reward = Tensor([reward]).to(device)\n",
    "        \n",
    "        if done:\n",
    "            target_value = reward\n",
    "        else:\n",
    "            new_state_values = self.nn(new_state).detach()\n",
    "            max_new_state_values = torch.max(new_state_values)\n",
    "            target_value = reward + gamma * max_new_state_values\n",
    "        \n",
    "        predicted_value = self.nn(state)[action]\n",
    "        \n",
    "        loss = self.loss_func(predicted_value, target_value)\n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        \n",
    "        #Q[state, action] = reward + gamma * torch.max(Q[new_state])\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "qnet_agent = QNet_Agent()\n",
    "\n",
    "steps_total = []\n",
    "\n",
    "frames_total = 0 \n",
    "solved_after = 0\n",
    "solved = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    step = 0\n",
    "    #for step in range(100):\n",
    "    while True:\n",
    "        \n",
    "        step += 1\n",
    "        frames_total += 1\n",
    "        \n",
    "        epsilon = calculate_epsilon(frames_total)\n",
    "        \n",
    "        #action = env.action_space.sample()\n",
    "        action = qnet_agent.select_action(state, epsilon)\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        qnet_agent.optimize(state, action, new_state, reward, done )\n",
    "        \n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            steps_total.append(step)\n",
    "            \n",
    "            mean_reward_100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if (mean_reward_100 > score_to_solve and solved == False):\n",
    "                print(\"SOLVED! After %i episodes \" % i_episode)\n",
    "                solved_after = i_episode\n",
    "                solved = True\n",
    "            \n",
    "            if (i_episode % report_interval == 0):\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(\"\\n*** Episode %i *** \\\n",
    "                      \\nAv.reward: [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f \\\n",
    "                      \\nepsilon: %.2f, frames_total: %i\" \n",
    "                  % \n",
    "                  ( i_episode,\n",
    "                    report_interval,\n",
    "                    sum(steps_total[-report_interval:])/report_interval,\n",
    "                    mean_reward_100,\n",
    "                    sum(steps_total)/len(steps_total),\n",
    "                    epsilon,\n",
    "                    frames_total\n",
    "                          ) \n",
    "                  )\n",
    "                  \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "\n",
    "\n",
    "            break\n",
    "        \n",
    "\n",
    "print(\"\\n\\n\\n\\nAverage reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average reward (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "if solved:\n",
    "    print(\"Solved after %i episodes\" % solved_after)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='green', width=5)\n",
    "plt.show()\n",
    "\n",
    "env.close()\n",
    "env.env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close env\n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
